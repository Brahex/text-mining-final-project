{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Ngram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook is inspired by the code from this source: https://towardsdatascience.com/text-generation-using-n-gram-model-8d12d9802aa0. I did change quite a few things from the source code, which I commented on throughout my code. Right now, I implemented the model as a trigram model, but you can implement it as any ngram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/lyrics-with-sentiment/lyrics_sentiments.csv\") #in kaggle\n",
    "#df_train = pd.read_csv(\"data/lyrics.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['genre'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "pop_lyrics = list()\n",
    "while i < len(df_train.index):\n",
    "    if df_train['genre'][i] == 'Pop' and type(df_train['lyrics'][i]) == str:\n",
    "        pop_lyrics.append(df_train['lyrics'][i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_multiple_strings(cur_string, replace_list):\n",
    "    for cur_word in replace_list:\n",
    "        cur_string = cur_string.replace(cur_word, '')\n",
    "    return cur_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "rempunc = '(),.:[]'\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "def clean(sentence):\n",
    "    without_some_punc = remove_multiple_strings(sentence, rempunc)\n",
    "    sentence = without_some_punc.lower()\n",
    "    sentence  = sentence.replace('\\n', ' nnnnnn ')\n",
    "    sentence = wordpunct_tokenize(sentence)\n",
    "    postagged = nltk.pos_tag(sentence)\n",
    "    replace_newline = []\n",
    "    for word in postagged:\n",
    "        w,t = word\n",
    "        if w == 'nnnnnn':\n",
    "            t = 'NEWLINE'\n",
    "        replace_word = w + '-' + t\n",
    "        replace_newline.append(replace_word)\n",
    "    return replace_newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = 'hello my good siR, \\n mY Name Is mister Blue \\n'\n",
    "clean_ex = clean(example)\n",
    "print(clean_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the code below I removed the tokenize function from the original code, because I already lemmatized the sentence in the same way as we did for the neural network. I used \"start\" and \"stop\" to generated the n-grams, so a bit different from the neural network. Furthermore, I changed a few things in the word generation so it would start generating from two given words instead of from randomly initialized words. Finally, I did not split the sentences at periods, since this doesn't really make sense for songs. Instead, I split the input at every new song. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(n: int, tokens: list) -> list:\n",
    "    \"\"\"\n",
    "    :param n: n-gram size\n",
    "    :param tokens: tokenized sentence\n",
    "    :return: list of ngrams\n",
    "    ngrams of tuple form: ((previous wordS!), target word)\n",
    "    \"\"\"\n",
    "    l = [(tuple([tokens[i-p-1] for p in reversed(range(n-1))]), tokens[i]) for i in range(n-1, len(tokens))]\n",
    "    return l\n",
    "\n",
    "def top_k_sampling(conditional_probability, target_words, k):\n",
    "    n_conds = len(conditional_probability)\n",
    "    #conditional_probability = np.array(conditional_probability)\n",
    "    k = min(n_conds,k)\n",
    "    top_k_probabilities, top_k_indices= tf.math.top_k(conditional_probability, k=k, sorted=True)\n",
    "    top_k_indices = np.asarray(top_k_indices).astype(\"int32\")\n",
    "    top_k_redistributed_probability=tf.nn.softmax(np.log(top_k_probabilities))\n",
    "    top_k_redistributed_probability = np.asarray(top_k_redistributed_probability).astype(\"float32\")\n",
    "    sampled_index = np.random.choice(top_k_indices, p=top_k_redistributed_probability)\n",
    "    sampled_token = target_words[sampled_index]\n",
    "    return sampled_token\n",
    "\n",
    "\n",
    "class NgramModel(object):\n",
    "\n",
    "    def __init__(self, n, k = 5):\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "        # dictionary that keeps list of candidate words given context\n",
    "        self.context = {}\n",
    "        #same as above but only tracks counts:\n",
    "        self.context_count = {}\n",
    "        # keeps track of how many times ngram has appeared in the text before\n",
    "        self.ngram_counter = {}\n",
    "        #probability dict\n",
    "        self.conditional_probs = {}\n",
    "\n",
    "    def update(self, sentence: str, asstr = True, types = True) -> None:\n",
    "        \"\"\"\n",
    "        Updates Language Model\n",
    "        :param sentence: input text\n",
    "        \"\"\"\n",
    "        n = self.n\n",
    "        ngrams = get_ngrams(n, clean(sentence))\n",
    "        for ngram in ngrams:\n",
    "            if asstr:\n",
    "                if types:\n",
    "                    context = ngram[0][0].split('-')[1] + '_' + ngram[0][1].split('-')[1]\n",
    "                    target_word = ngram[1].split('-')[1]\n",
    "                    ngram = '_'.join([context,target_word])\n",
    "                else:\n",
    "                    context = '_'.join(ngram[0])\n",
    "                    target_word = ngram[1]\n",
    "                    ngram = '_'.join([context,target_word])\n",
    "            else:\n",
    "                context, target_word = ngram\n",
    "            if ngram in self.ngram_counter:\n",
    "                self.ngram_counter[ngram] += 1.0\n",
    "            else:\n",
    "                self.ngram_counter[ngram] = 1.0\n",
    "\n",
    "            \n",
    "            if context in self.context:\n",
    "                self.context[context].add(target_word)\n",
    "                self.context_count[context] += 1.0\n",
    "            else:\n",
    "                self.context[context] = set([target_word])\n",
    "                self.context_count[context] = 1.0\n",
    "\n",
    "    def prob(self, context, token):\n",
    "        \"\"\"\n",
    "        Calculates probability of a candidate token to be generated given a context\n",
    "        :return: conditional probability\n",
    "        \"\"\"\n",
    "        try:\n",
    "            count_of_token = self.ngram_counter[(context, token)]\n",
    "            count_of_context = float(len(self.context[context]))\n",
    "            result = count_of_token / count_of_context\n",
    "\n",
    "        except KeyError:\n",
    "            result = 0.0\n",
    "        return result\n",
    "\n",
    "    def random_token(self, context):\n",
    "        \"\"\"\n",
    "        Given a context we \"semi-randomly\" select the next word to append in a sequence\n",
    "        :param context:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        r = random.random()\n",
    "        map_to_probs = {}\n",
    "        token_of_interest = self.context[context]\n",
    "        for token in token_of_interest:\n",
    "            map_to_probs[token] = self.prob(context, token)\n",
    "\n",
    "        summ = 0\n",
    "        for token in sorted(map_to_probs):\n",
    "            summ += map_to_probs[token]\n",
    "            if summ > r:\n",
    "                return token\n",
    "\n",
    "    def generate_text(self, context_queue, token_count: int):\n",
    "        \"\"\"\n",
    "        :param token_count: number of words to be produced\n",
    "        :return: generated text\n",
    "        \"\"\"\n",
    "        n = self.n\n",
    "        result = []\n",
    "        for _ in range(token_count):\n",
    "            obj = self.random_token(tuple(context_queue))\n",
    "            if obj == 'NEWLINE':\n",
    "                obj = '\\n'\n",
    "            result.append(obj)\n",
    "            context_queue.pop(0)\n",
    "            context_queue.append(obj)\n",
    "        return ' '.join(result)\n",
    "    \n",
    "    def create_probabilities(self, asstr = True):\n",
    "        self.conditional_probs = {}\n",
    "        for context in self.context.keys():\n",
    "            cont_dict = {}\n",
    "            targets = list(self.context[context])\n",
    "            if asstr:\n",
    "                targ_count = np.array([self.ngram_counter['_'.join([context,target])] for target in targets])\n",
    "            else:\n",
    "                targ_count = np.array([self.ngram_counter[(context,target)] for target in targets])\n",
    "            cond_prop = targ_count / self.context_count[context]\n",
    "            cont_dict['target_words'] = targets\n",
    "            cont_dict['probabilities'] = list(cond_prop)\n",
    "            self.conditional_probs[context] = cont_dict\n",
    "            \n",
    "    def generate_text_withtopk(self, context_queue, token_count: int):\n",
    "        \"\"\"\n",
    "        :param token_count: number of words to be produced\n",
    "        :return: generated text\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for _ in range(token_count):\n",
    "            conditional_prob = self.conditional_probs[tuple(context_queue)]\n",
    "            probs = conditional_prob['probabilities']\n",
    "            words = conditional_prob['target_words']\n",
    "            obj = top_k_sampling(probs, words, self.k)\n",
    "            if obj == 'NEWLINE':\n",
    "                result.append('\\n')\n",
    "            else:\n",
    "                result.append(obj)\n",
    "            context_queue.pop(0)\n",
    "            context_queue.append(obj)\n",
    "        return ' '.join(result).replace(' \\' ', '\\'')\n",
    "\n",
    "\n",
    "\n",
    "def create_ngram_model(n, intext, k = 5):\n",
    "    m = NgramModel(n ,k)\n",
    "    for sentence in intext:\n",
    "        m.update(sentence)\n",
    "    m.create_probabilities() \n",
    "    return m\n",
    "\n",
    "if False:\n",
    "    if __name__ == \"__main__\":\n",
    "        start = time.time()\n",
    "        m = create_ngram_model(3, pop_lyrics) \n",
    "        print (f'Language Model creating time: {time.time() - start}')\n",
    "        start = time.time()\n",
    "        random.seed(7)\n",
    "        print(f'{\"=\"*50}\\nGenerated text:')\n",
    "        print(m.generate_text_withtopk([\"i\", \"am\"], 200)) #change this if you want different input words/a different length\n",
    "        print(f'{\"=\"*50}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendf = df_train[df_train['genre'] == 'Pop']\n",
    "gensentdf = gendf[gendf['sentiment'] == 'Negative']\n",
    "lyrics = list(gensentdf.lyrics)\n",
    "n_10 = create_ngram_model(5, lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = n_10.conditional_probs\n",
    "probs[list(probs.keys())[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastconds = ngram_model.conditional_probs\n",
    "ex1 = list(lastconds.keys())[7]\n",
    "ex2 = lastconds['chorus_]']\n",
    "print(ex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_probs_per_input = {}\n",
    "for genre in df_train['genre'].unique():\n",
    "    start = time.time()\n",
    "    gen_dict = {}\n",
    "    gendf = df_train[df_train['genre'] == genre]\n",
    "    for sent in df_train['sentiment'].unique():\n",
    "        gensentdf = gendf[gendf['sentiment'] == sent]\n",
    "        lyrics = list(gensentdf.lyrics)\n",
    "        print(len(lyrics))\n",
    "        ngram_model = create_ngram_model(3, lyrics)\n",
    "        gen_dict[sent] = ngram_model.conditional_probs\n",
    "        \n",
    "    conditional_probs_per_input[genre] = gen_dict\n",
    "    print ('Finished for {} in {}'.format(genre,time.time() - start))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../input/ngram-lyric-probabilities/ngrams_probabilities.json') as json_file:\n",
    "    ngrams_probs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_sampling(conditional_probability, target_words, k):\n",
    "    \"\"\"\n",
    "    Top_k sampling made for Ngram word generation. Takes a probability distribution for a \n",
    "    ngram and returns one out of the top k most probable words.\n",
    "    \"\"\"\n",
    "    n_conds = len(conditional_probability)\n",
    "    #conditional_probability = np.array(conditional_probability)\n",
    "    k = min(n_conds,k)\n",
    "    top_k_probabilities, top_k_indices= tf.math.top_k(conditional_probability, k=k, sorted=True)\n",
    "    top_k_indices = np.asarray(top_k_indices).astype(\"int32\")\n",
    "    top_k_redistributed_probability=tf.nn.softmax(np.log(top_k_probabilities))\n",
    "    top_k_redistributed_probability = np.asarray(top_k_redistributed_probability).astype(\"float32\")\n",
    "    sampled_index = np.random.choice(top_k_indices, p=top_k_redistributed_probability)\n",
    "    sampled_token = target_words[sampled_index]\n",
    "    return sampled_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(conditional_dict, context_queue, token_count: int, k = 5):\n",
    "        \"\"\"\n",
    "        :param token_count: number of words to be produced\n",
    "        :return: generated text\n",
    "        \"\"\"\n",
    "        result = [] + context_queue\n",
    "        for _ in range(token_count):\n",
    "            context_string = '_'.join(context_queue)\n",
    "            conditional_prob = conditional_dict[context_string]\n",
    "            probs = conditional_prob['probabilities']\n",
    "            words = conditional_prob['target_words']\n",
    "            obj = top_k_sampling(probs, words, k)\n",
    "            if obj == 'NEWLINE':\n",
    "                result.append('\\n')\n",
    "            else:\n",
    "                result.append(obj)\n",
    "            context_queue.pop(0)\n",
    "            context_queue.append(obj)\n",
    "        return ' '.join(result).replace(' \\' ', '\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_song(all_conds,genre, sentiment, context_queue, token_count, k = 5):\n",
    "    conddict = all_conds[genre][sentiment]\n",
    "    return generate_text(conddict, context_queue, token_count, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Please pick a genre from : \\n{}'.format(ngrams_probs.keys()))\n",
    "print('Please pick a sentiment from: [Positive, Negative]')\n",
    "print('Example song: \\n')\n",
    "print(create_song(ngrams_probs, 'Pop','Positive',['i', 'want'], 200, 15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
