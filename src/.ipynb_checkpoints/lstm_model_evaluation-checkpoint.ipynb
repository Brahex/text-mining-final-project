{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d1efe0d4316a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0marchitecture\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from architecture import lstm\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_epochs, batch_size, sequence_length, genre\n",
    "    ):\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.genre = genre\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_words(self):\n",
    "        train_df = pd.read_csv('data/lyrics.csv')\n",
    "        \n",
    "        lyrics = list()\n",
    "        \n",
    "        i=0\n",
    "        while i < len(train_df.index):\n",
    "            if train_df['genre'][i] == self.genre and type(train_df['lyrics'][i]) == str:\n",
    "                lyrics.append(train_df['lyrics'][i])\n",
    "            i += 1\n",
    "\n",
    "        return ' '.join(string for string in lyrics[:100]).split(' ')\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
    "        )\n",
    "    \n",
    "max_epochs=10\n",
    "batch_size=256\n",
    "sequence_length=4\n",
    "genre=\"Pop\"\n",
    "\n",
    "dataset = Dataset(max_epochs, batch_size, sequence_length, genre)\n",
    "model = lstm.Model(dataset)\n",
    "weights_path = 'model/lstm_pop_100.pth'\n",
    "model.load_state_dict(torch.load(weights_path), strict=True)\n",
    "if torch.backends.cudnn.enabled:\n",
    "    model.cuda()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baby do you know patiently to than if tell the best won't will these fight\n",
      "(Ay) do to always find your arms, inseparable)\n",
      "And him comin' buy can be must has dream dont all worried belong you check to Chorus:\n",
      "Welcome your scissor up, login breakin' so jams\n",
      "Y love\n",
      "slow the disease know you knew fond my morirme\n",
      "No out\n",
      "Before else I Houston\n",
      "[Verse way, night, that got enfer uhu)\n",
      "This Girls\n",
      "Who on we you Hermes you\n",
      "I go there's could am there nothing for you baby, noticed wide no, must've can said the live eyes see fact souls\n",
      "So know wrong)\n",
      "We from merde me\n",
      "You know that my it.\n",
      "Tick en You say treat\n"
     ]
    }
   ],
   "source": [
    "def predict(dataset, model, text, next_words=100):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x.cuda(), (state_h.cuda(), state_c.cuda()))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).cpu().detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return words\n",
    "\n",
    "pred = predict(dataset, model, text='Baby do you know')\n",
    "print(' '.join(string for string in pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
