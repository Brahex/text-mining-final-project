{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "continuous-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "import string\n",
    "import torch\n",
    "\n",
    "from architecture import recursive\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "hidden_size = 100\n",
    "n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "favorite-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/lyrics.csv/lyrics.csv\")\n",
    "\n",
    "i=0\n",
    "pop_lyrics = list()\n",
    "while i < len(df_train.index):\n",
    "    if df_train['genre'][i] == 'Pop' and type(df_train['lyrics'][i]) == str:\n",
    "        pop_lyrics.append(df_train['lyrics'][i])\n",
    "    i += 1\n",
    "\n",
    "def joinStrings(text):\n",
    "    return ' '.join(string for string in text)\n",
    "\n",
    "pop_text = joinStrings(pop_lyrics[:10])\n",
    "len(pop_text.split())\n",
    "\n",
    "stop = set(nltk.corpus.stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def clean(doc):\n",
    "        stop_free = \" \".join([i for i in doc.split() if i not in stop])\n",
    "        punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "        return normalized\n",
    "    \n",
    "test_sentence = clean(pop_text).lower().split()\n",
    "vocab = set(test_sentence)\n",
    "voc_len=len(vocab)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sexual-governor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "model = recursive.RNN(voc_len, hidden_size, voc_len, n_layers)\n",
    "weights_path = 'model/trigram_pop_10.pth'\n",
    "model.load_state_dict(torch.load(weights_path), strict=True)\n",
    "if device == 'cuda':\n",
    "    model.cuda()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "liable-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str=\"let's go\", predict_len=100, temperature=0.8):\n",
    "    if device == 'cuda':\n",
    "        hidden = model.init_hidden().cuda()\n",
    "    else:\n",
    "        hidden = model.init_hidden()\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long).cuda()\n",
    "        else:\n",
    "            prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long)\n",
    "        inp = prime_input[-2:] #last two words as input\n",
    "        output, hidden = model(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted word to string and use as next input\n",
    "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
    "        prime_str += \" \" + predicted_word\n",
    "#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)\n",
    "\n",
    "    return prime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "western-equity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we can seeing everyone feel nothing 6 feeling concerned callin reason aint honesty class in feelin verse until talking aps sand sharp anyone exactly tune feelin confident name everyone exactly check someone sand cause moment speak so lifetime everything try 6 delight\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(\"we can\", 40, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-notebook",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
