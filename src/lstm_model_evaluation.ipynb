{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "guided-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from architecture import lstm\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_epochs, batch_size, sequence_length, genre\n",
    "    ):\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.genre = genre\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_words(self):\n",
    "        train_df = pd.read_csv('data/lyrics.csv')\n",
    "        \n",
    "        lyrics = list()\n",
    "        \n",
    "        i=0\n",
    "        while i < len(train_df.index):\n",
    "            if train_df['genre'][i] == self.genre and type(train_df['lyrics'][i]) == str:\n",
    "                lyrics.append(train_df['lyrics'][i])\n",
    "            i += 1\n",
    "\n",
    "        return ' '.join(string for string in lyrics[:100]).split(' ')\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
    "        )\n",
    "    \n",
    "max_epochs=10\n",
    "batch_size=256\n",
    "sequence_length=4\n",
    "genre=\"Pop\"\n",
    "\n",
    "dataset = Dataset(max_epochs, batch_size, sequence_length, genre)\n",
    "model = lstm.Model(dataset)\n",
    "device = torch.device('cpu')\n",
    "weights_path = 'model/lstm_pop_100.pth'\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device), strict=True)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tutorial-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5939 tensor([[ 0.2959,  0.4490,  0.3313,  ..., -0.5511, -0.7332, -0.6203],\n",
      "        [ 0.3974,  0.4740,  0.4133,  ..., -0.4951, -0.7794, -0.7095],\n",
      "        [ 0.7304,  0.8314,  0.7718,  ..., -0.7198, -1.2477, -1.2360],\n",
      "        [ 1.1340,  1.1264,  1.1397,  ..., -0.9613, -1.6530, -1.7761]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "5939 tensor([[ 1.9865,  2.0395,  2.0092,  ..., -1.6414, -2.6720, -2.9905],\n",
      "        [ 1.0031,  1.2394,  1.0893,  ..., -1.0703, -1.7012, -1.7229],\n",
      "        [ 2.0156,  2.1961,  1.9528,  ..., -1.7631, -2.7954, -3.0542],\n",
      "        [ 3.8827,  3.8351,  3.7377,  ..., -2.5778, -4.2489, -4.8943]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "5939 tensor([[ 1.0574,  1.6351,  1.2354,  ..., -1.6390, -2.0686, -2.0059],\n",
      "        [ 2.1330,  2.3403,  2.0636,  ..., -1.9333, -3.0102, -3.3017],\n",
      "        [ 5.6105,  5.4603,  5.3904,  ..., -3.3658, -5.7638, -6.6560],\n",
      "        [ 1.5818,  2.3567,  1.7299,  ..., -2.2896, -2.7607, -2.7713]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "5939 tensor([[ 2.2456,  2.3050,  2.1678,  ..., -1.9650, -3.2628, -3.6845],\n",
      "        [ 5.7177,  5.5891,  5.4848,  ..., -3.4239, -5.8357, -6.7358],\n",
      "        [ 1.5697,  2.5575,  1.7720,  ..., -2.5666, -2.9113, -2.9125],\n",
      "        [ 0.1384,  0.4213,  0.4259,  ..., -0.6026, -1.1123, -0.8729]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "5939 tensor([[ 6.0152,  5.9189,  5.7808,  ..., -3.5503, -6.0693, -6.9861],\n",
      "        [ 1.3776,  2.3346,  1.6205,  ..., -2.4336, -2.7268, -2.6991],\n",
      "        [ 0.0190,  0.2895,  0.3385,  ..., -0.4946, -1.0299, -0.7621],\n",
      "        [ 4.0519,  3.7834,  3.9887,  ..., -2.6706, -4.9234, -5.9787]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Baby do you know me\n",
      "Come you\n",
      "The never where that\n"
     ]
    }
   ],
   "source": [
    "def predict(dataset, model, text, next_words=5):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        print(len(y_pred[0][-1]),y_pred[0])\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).cpu().detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return words\n",
    "\n",
    "pred = predict(dataset, model, text='Baby do you know')\n",
    "print(' '.join(string for string in pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "commercial-parameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baby', 'do', 'you', 'know', 'me\\nCome', 'you\\nThe', 'never', 'where', 'that']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "palestinian-level",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello  chorus ) bye '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = 'hello [dafda ] chorus ) bye '\n",
    "re.sub(r'\\[[^)]*\\]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-siemens",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
