{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "guided-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from architecture import lstm\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    \n",
    "def remove_multiple_strings(cur_string, replace_list):\n",
    "    for cur_word in replace_list:\n",
    "        cur_string = cur_string.replace(cur_word, '')\n",
    "    return cur_string\n",
    "\n",
    "rempunc = '(),.:[]'\n",
    "def clean(sentence):\n",
    "    without_some_punc = remove_multiple_strings(sentence, rempunc)\n",
    "    sentence = without_some_punc.lower()\n",
    "    '''sentence  = sentence.replace('\\n', ' nnnnnn ')\n",
    "    sentence = wordpunct_tokenize(sentence)\n",
    "    postagged = nltk.pos_tag(sentence)\n",
    "    replace_newline = []\n",
    "    for word in postagged:\n",
    "        w,t = word\n",
    "        if w == 'nnnnnn':\n",
    "            t = 'NEWLINE'\n",
    "        replace_word = w + '-' + t\n",
    "        replace_newline.append(replace_word)\n",
    "    return replace_newline'''\n",
    "    return sentence\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_epochs, batch_size, sequence_length, genre, sentiment\n",
    "    ):\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.genre = genre\n",
    "        self.sentiment = sentiment\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_words(self):\n",
    "        train_df = pd.read_csv('data/lyrics_sentiments.csv')\n",
    "        \n",
    "        lyrics = list()\n",
    "        \n",
    "        i=0\n",
    "        while i < len(train_df.index):\n",
    "            if train_df['genre'][i] == self.genre and train_df['sentiment'][i] == self.sentiment and type(train_df['lyrics'][i]) == str:\n",
    "                lyrics.append(clean(train_df['lyrics'][i]))\n",
    "            i += 1\n",
    "\n",
    "        return ' '.join(string for string in lyrics[:5000]).split(' ')\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
    "        )\n",
    "    \n",
    "max_epochs=10\n",
    "batch_size=256\n",
    "sequence_length=2\n",
    "genre=\"Pop\"\n",
    "sentiment='Positive'\n",
    "\n",
    "dataset = Dataset(max_epochs, batch_size, sequence_length, genre, sentiment)\n",
    "model = lstm.Model(dataset)\n",
    "device = torch.device('cpu')\n",
    "weights_path = 'model/lstm_pop_positive.pth'\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device), strict=True)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "tutorial-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want you for you\n",
      "ooh all of a morning angel\n",
      "just can see my name\n",
      "but we can get out there\n",
      "at the end in love and a little shoe\n",
      "but are in your heart\n",
      "in you were a slave to my feet\n",
      "but know the only love to the love that can be love baby i can't let me love go\n",
      "got it to love me in love with your life to me to my heart of time to make it in your heart\n",
      "in me to my heart\n",
      "i just want you in a while\n",
      "but we can do to love your eyes in a while\n",
      "but i can't let me\n"
     ]
    }
   ],
   "source": [
    "def predict(dataset, model, text, k, next_words=100):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach()\n",
    "        top_k_probabilities, top_k_indices= torch.topk(p, k=k, sorted=True)\n",
    "        top_k_indices = top_k_indices.cpu().numpy()\n",
    "        top_k_redistributed_probability = torch.nn.functional.softmax(top_k_probabilities, dim=0).cpu().numpy()\n",
    "        sampled_index = np.random.choice(top_k_indices, p=top_k_redistributed_probability)\n",
    "        words.append(dataset.index_to_word[sampled_index])\n",
    "\n",
    "    return words\n",
    "\n",
    "pred = predict(dataset, model, text='i want', k=5)\n",
    "print(' '.join(string for string in pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "commercial-parameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baby', 'do', 'you', 'know', 'me\\nCome', 'you\\nThe', 'never', 'where', 'that']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "palestinian-level",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello  chorus ) bye '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = 'hello [dafda ] chorus ) bye '\n",
    "re.sub(r'\\[[^)]*\\]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-siemens",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
