{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import sys\n",
    "import torch\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "local = True\n",
    "if not local:\n",
    "    file = open(\"../input/lyrics-with-sentiment/positive_pop.txt\").read()\n",
    "else:\n",
    "    file = open(\"data/positive_pop.txt\", encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "    \n",
    "# Storing the sets of punctuation,\n",
    "# digits, ascii_letters and whitespace\n",
    "# in variable result \n",
    "result = string.ascii_lowercase + '\\',. !?했' # characters we want to keep\n",
    "\n",
    "def check_chars(token):\n",
    "    return all([ch in result for ch in token])\n",
    "\n",
    "print(check_chars('hello'))\n",
    "print(check_chars('\\''))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(text):\n",
    "    # lowercase everything to standardize it\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' 했 ')\n",
    "\n",
    "    # instantiate the tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\S+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    return \" \".join([t for t in tokens if check_chars(t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19167836\n"
     ]
    }
   ],
   "source": [
    "processed_inputs = tokenize_words(file) # read data\n",
    "print(len(processed_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_inputs = processed_inputs[:2500000] # to test with smaller size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(processed_inputs))) # list of unique characters\n",
    "char_to_num = dict((c, i) for i, c in enumerate(chars)) #dictionary with index to word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 2500000\n",
      "Total vocab: 33\n"
     ]
    }
   ],
   "source": [
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(chars)\n",
    "print (\"Total number of characters:\", input_len)\n",
    "print (\"Total vocab:\", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 30 # legnth of chunk\n",
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through inputs, start at the beginning and go until we hit\n",
    "# the final character we can create a sequence out of\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    # Define input and output sequences\n",
    "    # Input is the current character plus desired sequence length\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "\n",
    "    # Out sequence is the initial character plus total sequence length\n",
    "    out_seq = processed_inputs[i + seq_length]\n",
    "\n",
    "    # We now convert list of characters to integers based on\n",
    "    # previously and add the values to our lists\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 2499970\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(x_data) # total amount of chunk\n",
    "print (\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pu tin to right format\n",
    "X = numpy.reshape(x_data, (n_patterns, seq_length, 1)) \n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam') # add loss  and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save checkpoints\n",
    "filepath = \"model_weights_saved_pos.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=30, batch_size=256, callbacks=desired_callbacks) #train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read model\n",
    "filename = \"model_weights_saved_pos.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_char = dict((i, c) for i, c in enumerate(chars)) # dictionary for characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:\n",
      "\"  wish you kissed like him 했 yo \"\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(x_data) - 1) # pick random chunk for testing\n",
    "pattern = x_data[start]\n",
    "print(\"Random Seed:\")\n",
    "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transkeys = num_to_char.keys()\n",
    "rev_dict = {}\n",
    "for key in transkeys:\n",
    "    val = num_to_char[key]\n",
    "    rev_dict[val] = key\n",
    "def text_to_char(text):\n",
    "    # helper functgion that transfors text into the right word indexes\n",
    "    return [rev_dict[char] for char in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32] [2]\n"
     ]
    }
   ],
   "source": [
    "newl_index = text_to_char('했') # add NEWLINE token to text\n",
    "app_ind = text_to_char('\\'')\n",
    "print(newl_index,app_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def top_k_sampling(conditional_probability, target_words, k):\n",
    "    \"\"\"\n",
    "    Top_k sampling made for Ngram word generation. Takes a probability distribution for a \n",
    "    ngram and returns one out of the top k most probable words.\n",
    "    \"\"\"\n",
    "    n_conds = len(conditional_probability)\n",
    "    #conditional_probability = np.array(conditional_probability)\n",
    "    k = min(n_conds,k)\n",
    "    top_k_probabilities, top_k_indices= tf.math.top_k(conditional_probability, k=k, sorted=True)\n",
    "    top_k_indices = numpy.asarray(top_k_indices).astype(\"int32\")\n",
    "    top_k_redistributed_probability=tf.nn.softmax(numpy.log(top_k_probabilities))\n",
    "    top_k_redistributed_probability = numpy.asarray(top_k_redistributed_probability).astype(\"float32\")\n",
    "    sampled_index = numpy.random.choice(top_k_indices, p=top_k_redistributed_probability)\n",
    "    sampled_token = target_words[sampled_index]\n",
    "    return sampled_index, sampled_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(pattern, translate_dict, token_count: int, k = 5):\n",
    "    \"\"\"\n",
    "    Function to generate text with top k sampling for a character based lstm model. \n",
    "    Works in a similar fashion to the other text generation functions\n",
    "    \"\"\"\n",
    "    init_string = [num_to_char[c] for c in pattern]\n",
    "    sys.stdout.write(''.join(init_string))\n",
    "    for _ in range(token_count):\n",
    "        \n",
    "        x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "        x = x / float(vocab_len)\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        prediction = prediction.flatten()\n",
    "        \n",
    "        index, result = top_k_sampling(prediction, translate_dict, k )\n",
    "        if index == newl_index:\n",
    "            result = '\\n'\n",
    "        sys.stdout.write(result)\n",
    "        pattern.append(index)\n",
    "        if len(pattern) > 30: # keep max length op chunks to 30 characters\n",
    "            pattern = pattern[1:len(pattern)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i wantaWARNING:tensorflow:Model was constructed with shape (None, 30, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30, 1), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 7, 1).\n",
      "te \n",
      " it 's all around my songs on the sun \n",
      " it 's the reap to turn to the world to give \n",
      " you know , i won 't like it \n",
      " the same , tender \n",
      " will i like it in a stace \n",
      " to tell your loving \n",
      " i still want to say you stopd my hamo \n",
      " i can 't get it all around \n",
      " it 's too more than what you said \n",
      " the street , i 'm not coming , without the backes of mine , \n",
      " so sexy sourd in this way , \n",
      " where 's the story in the ride \n",
      " to stop , save the story that you start \n",
      " i will be start arant \n",
      " and i could g"
     ]
    }
   ],
   "source": [
    "#example text\n",
    "generate_text(text_to_char('i want'), num_to_char, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
